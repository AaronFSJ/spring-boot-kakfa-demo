server.port=8098
spring.kafka.bootstrap-servers=192.168.1.4:9092
#spring.kafka.bootstrap-servers=192.168.1.4:9092,192.168.1.4:9093,192.168.1.4:9094


spring.kafka.consumer.group-id=test
#enable.auto.commit=true 如果为true，消费者的偏移量将在后台定期提交。
spring.kafka.consumer.enable-auto-commit=false
#如果设置为自动提交（enable.auto.commit=true），这里设置自动提交周期
spring.kafka.consumer.auto-commit-interval=6000
spring.kafka.consumer.auto-offset-reset=earliest
#以下key-deserializer和value-deserializer可以不指定，因为spring boot默认就是用此String序列化,但是如果指定了之后，存入的key或者value为空，就会报错
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#以下key-deserializer和value-deserializer可以不指定，因为spring boot默认就是用此String序列化,但是如果指定了之后，存入的key或者value为空，就会报错
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

spring.kafka.producer.acks=all
spring.kafka.listener.poll-timeout=3000







####例子
#bootstrap.servers=192.168.49.206:9092,192.168.49.205:9092,192.168.49.204:9092 brokers集群
#acks=all     即所有副本都同步到数据时send方法才返回, 以此来完全判断数据是否发送成功, 理论上来讲数据不会丢失.
#retries=10 发送失败重试次数
#batch.size=1638 批处理条数：当多个记录被发送到同一个分区时，生产者会尝试将记录合并到更少的请求中。这有助于客户端和服务器的性能。
#linger.ms=1 批处理延迟时间上限：即1ms过后，不管是否达到批处理数，都直接发送一次请求
#buffer.memory=33554432 即32MB的批处理缓冲区
#
#group.id=order-beta  消费者群组ID，发布-订阅模式，即如果一个生产者，多个消费者都要消费，那么需要定义自己的群组，同一群组内的消费者只有一个能消费到消息
#enable.auto.commit=true 如果为true，消费者的偏移量将在后台定期提交。
#auto.commit.interval.ms=1000 如何设置为自动提交（enable.auto.commit=true），这里设置自动提交周期
#session.timeout.ms=15000 在使用Kafka的组管理时，用于检测消费者故障的超时
#concurrency = 3 消费监听器容器并发数


#以下为一个真实的公司要求的使用规范：
#
#a: Producer 部分参数设定:
#
#　　1: acks 设置为 "all" 即所有副本都同步到数据时send方法才返回, 以此来完全判断数据是否发送成功, 理论上来讲数据不会丢失.
#
#　　　　2: retries = MAX 无限重试，直到你意识到出现了问题.
#
#　　　　3: 使用 callback 来处理消息失败发送逻辑.
#
#　　　　4: min.insync.replicas > 1 消息至少要被写入到这么多副本才算成功，也是提升数据持久性的一个参数。与acks配合使用.
#
#　　　　5: 其他一些超时参数: reconnect.backoff.ms, retry.backoff.ms , linger.ms 结合 batch.size 等.
#

#
#b: Consumer 部分参数设定:
#
#1: auto.offset.reset 设置为 "earliest" 避免 offset 丢失时跳过未消费的消息. 目前消息存储不统一, 部分使用 zookeeper, 部分使用 kafka topic.
#
#2: enable.auto.commit=false  关闭自动提交位移, 在消息被完整处理之后再手动提交位移.
#
#3: consumer 的并发受 partition 的限制. 如果消息处理量比较大的情况请提前与运维联系, 增加 partition 数量应对消费端并发. 默认topic partition 为6-8个.
#
#partition 也不是越多越好. 首先会增加 file 和 memory, 其次会延长选举时间, 并且会延长 offset 的查询时间.  partition可以扩容但无法缩减.
#
#
#
#
#
#极限情况的数据丢失现象.
#
#a: 即使将 ack 设置为 "all" 也会在一定情况下丢失消息. 因为 kafka 的高性能特性, 消息在写入 kafka 时并没有落盘 而是写入了 OS buffer 中. 使用 OS 的脏页刷新策略周期性落盘, 就算落盘 仍然会有 raid buffer. 前者机器宕机数据丢失, 后者机器跳电数据丢失.
#
#b: 对数据可靠性较高的场景建议 offset 手动提交. 自动提交当遇到业务系统上线被关闭时, 消息读取并且 offset 已经提交, 但是数据没有存储或者仍没来得及消费时, 消息状态在内存中无法保留, 重启应用会跳过消息 致使消息丢失.
